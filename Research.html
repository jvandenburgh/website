
<!DOCTYPE html>
<html lang="en">
<title>Jonathan Vandenburgh</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body,h1,h2,h3,h4,h5,h6 {font-family: "Lato", sans-serif}
.w3-bar,h1,button {font-family: "Montserrat", sans-serif}
</style>
<body>

<!-- Navbar -->
<div class="w3-top">
  <div class="w3-bar w3-blue-gray w3-card w3-center w3-large">
    <a class="w3-bar-item w3-button w3-hide-medium w3-hide-large w3-right w3-padding-large w3-hover-white w3-large w3-white" href="javascript:void(0);" onclick="myFunction()" title="Toggle Navigation Menu"><i class="fa fa-bars"></i></a>
    <a href="http://www.jvandenburgh.com" class="w3-bar-item w3-button w3-padding-large w3-hover-white">Home</a>
    <a href="Research.html" class="w3-bar-item w3-button w3-hide-small w3-padding-large w3-white">Research</a>
    <a href="CV.pdf" target="_blank" class="w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white">Curriculum Vitae</a>
  </div>

  <!-- Navbar on small screens -->
  <div id="navDemo" class="w3-bar-block w3-white w3-hide w3-large">
    <a href="Research.html" class="w3-bar-item w3-button w3-padding-large">Research</a>
    <a href="CV.pdf" target="_blank" class="w3-bar-item w3-button w3-padding-large">Curriculum Vitae</a>
  </div>
</div>

<!-- Header -->
<header class="w3-container w3-left-align w3-light-gray" style="padding:64px 64px 32px">
  <h1 class="w3-margin w3-giant">Jonathan Vandenburgh </h1>
</header> 

<div class="w3-row-padding w3-padding-32 w3-container">
  <div class="w3-content w3-left-align">
      <h4>My research focuses on expressions of uncertainty and modality in language and factors influencing the formation of beliefs. My dissertation develops a model of how relevant alternatives factor into reasoning, applying this model to the meaning and epistemology of conditionals, the theory of knowledge, and the epistemology of stereotyping. I am currently developing projects on utility theory as a model of reasoning and on the epistemology of classification.</h4>
  </div>
  <div class="w3-content w3-left-align" style="padding: 16px 0px 0px">
      <h4> Below, you can find a list of papers. For papers not available online, please contact me if you would like to see a draft.</h4>
      <h4> <u>Conditional Learning Through Causal Models </u> </h4>
      <p> Available in <i> Synthese</i>: <a href="https://rdcu.be/b7VNz" target="_blank"> https://rdcu.be/b7VNz<a/></p>
      <p> Conditional learning, where agents learn a conditional sentence 'If A, then B,' is difficult to incorporate into existing Bayesian models of learning. This is because conditional learning is not uniform: in some cases, learning a conditional requires decreasing the probability of the antecedent, while in other cases, the antecedent probability stays constant or increases. I argue that how one learns a conditional depends on the causal structure relating the antecedent and the consequent, leading to a causal model of conditional learning. This model extends traditional Bayesian learning by incorporating causal models into agents' epistemic states. On this theory, conditional learning proceeds in two steps. First, an agent learns a new causal model with the appropriate relationship between the antecedent and the consequent. Then, the agent narrows down the set of possible worlds to include only those which make the conditional proposition true. This model of learning can incorporate both standard cases of Bayesian learning and the non-uniform learning required to learn conditional information. </p>
      <h4 style="padding: 16px 0px 0px"> <u> Causal Models and the Logic of Counterfactuals </u> </b> </h4>
      <p> Available on PhilPapers: <a href="https://philpapers.org/archive/VANCMA-6.pdf" target="_blank" >https://philpapers.org/archive/VANCMA-6.pdf<a/></p>
      <p> Causal models provide a framework for making counterfactual predictions, making them useful for evaluating the truth conditions of counterfactual sentences. However, current causal models for counterfactual semantics face logical limitations compared to the alternative similarity-based approaches: they only apply to a limited subset of counterfactuals and the connection to counterfactual logic is not straightforward. This paper offers a causal framework for the semantics of counterfactuals which improves upon these logical issues. It extends the causal approach to counterfactuals to handle more complex counterfactuals, including backtracking counterfactuals and those with logically complex antecedents. It also uses the notion of causal worlds to define a selection function and shows that this selection function satisfies familiar logical properties. While some limitations still arise, especially regarding counterfactuals which require breaking the laws of the causal model, this model improves upon many of the existing logical limitations of causal models. </p>
      <h4> <u>Causal Models and the Relevant Alternatives Theory of Knowledge </u> </h4>
      <p> Available on PhilPapers: <a href="https://philpapers.org/archive/VANCMA-7.pdf" target="_blank" >https://philpapers.org/archive/VANCMA-7.pdf<a/></p>
      <p> One approach to knowledge, termed the relevant alternatives theory, stipulates that a belief amounts to knowledge if one can eliminate all relevant alternatives to the belief in the epistemic situation. This paper uses causal graphical models to formalize the relevant alternatives approach to knowledge. On this theory, an epistemic situation is encoded through the causal relationships between propositions, which determine which alternatives are relevant and irrelevant. This formalization entails that statistical evidence is not sufficient for knowledge, provides a simple way to incorporate epistemic contextualism, and can rule out many Gettier cases from knowledge. The interpretation in terms of causal models offers more precise predictions for the relevant alternatives theory, strengthening the case for it as a theory of knowledge. </p>
      <h4> <u> Triviality Results, Conditional Probability, and Restrictor Conditionals </u></h4>
      <p> Available on PhilPapers: <a href="https://philpapers.org/archive/VANTRC-4.pdf" target="_blank" >https://philpapers.org/archive/VANTRC-4.pdf</a></p>
      <p> Conditional probability is often used to represent the probability of the conditional. However, triviality results suggest that the thesis that the probability of the conditional always equals conditional probability leads to untenable conclusions. In this paper, I offer an interpretation of this thesis in a possible worlds framework, arguing that the triviality results make assumptions at odds with the use of conditional probability. I argue that these assumptions come from a theory called the operator theory and that the rival restrictor theory can avoid these problematic assumptions. In doing so, I argue that recent extensions of the triviality arguments to restrictor conditionals fail, making assumptions which are only justified on the operator theory.</p>     
      <h4> <u> Learning as Hypothesis Testing: Learning Conditional and Probabilistic Information </u> </h4>
      <p> The history of science is often conceptualized through 'paradigm shifts,' where the accumulation of evidence leads to abrupt changes in scientific theories. Experimental evidence suggests that this kind of hypothesis revision occurs in more mundane circumstances, such as when children learn concepts and when adults engage in strategic behavior. In this paper, I argue that the model of hypothesis testing can explain how people learn certain complex, theory-laden propositions such as conditional sentences ('If A, then B') and probabilistic constraints ('The probability that A is p'). Theories are formalized as probability distributions over a set of possible outcomes and theory change is triggered by a constraint which is incompatible with the initial theory. This leads agents to consult a higher order probability function, or a 'prior over priors,' to choose the most likely alternative theory which satisfies the constraint. The hypothesis testing model is applied to three examples: a simple probabilistic constraint involving coin bias, the sundowners problem for conditional learning, and the Judy Benjamin problem for learning conditional probability constraints. The model of hypothesis testing is contrasted with the more conservative learning theory of relative information minimization, which dominates current approaches to learning conditional and probabilistic information.
      <!--<h4><u> Generics, Stereotypes, and Causal Models </u></h4>-->
  </div>
</div>



<script>
function myFunction() {
  var x = document.getElementById("navDemo");
  if (x.className.indexOf("w3-show") == -1) {
    x.className = x.className.replace("w3-hide", "w3-show");
  } else { 
    x.className = x.className.replace("w3-show", "w3-hide");
  }
}
</script>

</body>
</html>